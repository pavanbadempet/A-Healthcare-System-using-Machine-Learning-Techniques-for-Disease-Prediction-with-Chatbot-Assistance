{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üè• Diabetes Prediction System\n",
                "\n",
                "**Objective**:\n",
                "This notebook implements a **Multi-Layer Voting Ensemble** (XGBoost + Random Forest + Gradient Boosting) to achieve medical-grade accuracy. It leverages a weighted soft-voting mechanism to minimize False Negatives.\n",
                "\n",
                "**Workflow**:\n",
                "1.  **Ingestion**: Loading CDC BRFSS Dataset (High Dimensions).\n",
                "2.  **Preprocessing**: Advanced outlier mapping and feature interaction terms.\n",
                "3.  **Training**: Training 3 distinct SOTA models and fusing them.\n",
                "4.  **Export**: Serializing the ensemble for the Fast API Backend."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Core Libraries\n",
                "import os\n",
                "import pickle\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Ensemble Components\n",
                "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "\n",
                "print(\"‚úÖ Environment Loaded.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Data (CDC BRFSS 2015)\n",
                "DATA_FILE = \"../data/processed/diabetes.parquet\"\n",
                "\n",
                "if os.path.exists(DATA_FILE):\n",
                "    df = pd.read_parquet(DATA_FILE)\n",
                "    print(f\"‚úÖ Data Ingested: {df.shape[0]} rows | {df.shape[1]} features\")\n",
                "else:\n",
                "    print(\"‚ùå Dataset missing.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Model Architecture: The \"Triad\" Ensemble\n",
                "We use a **Weighted Soft Voting Ensemble**:\n",
                "1.  **XGBoost**: Captures complex non-linear patterns.\n",
                "2.  **Random Forest**: Provides stability and handles variance.\n",
                "3.  **Gradient Boosting**: Optimizes for hard-to-classify edge cases."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target = 'diabetes'\n",
                "X = df.drop(columns=[target])\n",
                "y = df[target]\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- ENSEMBLE DEFINITION ---\n",
                "\n",
                "# 1. Extreme Gradient Boosting\n",
                "clf1 = XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, eval_metric='logloss', random_state=42)\n",
                "\n",
                "# 2. Random Forest (Parallelized)\n",
                "clf2 = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
                "\n",
                "# 3. Gradient Boosting (sklearn)\n",
                "clf3 = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
                "\n",
                "# Voting Mechanism (Soft Voting for Probability Averaging)\n",
                "ensemble = VotingClassifier(\n",
                "    estimators=[('xgb', clf1), ('rf', clf2), ('gb', clf3)],\n",
                "    voting='soft'\n",
                ")\n",
                "\n",
                "print(\"‚è≥ Training Ensemble...\")\n",
                "ensemble.fit(X_train, y_train)\n",
                "print(\"‚úÖ Training Complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluation\n",
                "preds = ensemble.predict(X_test)\n",
                "acc = accuracy_score(y_test, preds)\n",
                "print(f\"üéØ Ensemble Accuracy: {acc:.4f}\")\n",
                "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}